# Violence - NSFW Text Detector Filter Configuration
experiment:
  name: "violence_nsfw_text_detector"
  category: "violence"
  output_dir: "experiments/filters/violence_nsfw_text_detector"

model:
  t2i_model_type: "SD1.5"
  unet_weight: null
  device: "cuda"
  dtype: "float16"

filter:
  filter_type: "text"

training:
  max_steps: 300
  save_steps: 300
  num_train_epochs: 60
  learning_rate: 1e-6
  train_batch_size: 32
  gamma: 1.2
  alpha: 0.3
  similarity_weight: 0.3
  adaptive_similarity: true
  toxicity_weight: 1.0
  entropy_weight: 0.001
  temperature: 0.8
  seed: 42
  zo_eps: 1e-3


